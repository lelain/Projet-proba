\documentclass[a4paper]{report}	

% Chargement d'extensions
\usepackage[utf8]{inputenc}     % Pour utiliser les lettres accentuées
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{cases}
\usepackage{mathrsfs}
\usepackage [francais]{babel}     % Pour la langue française
\usepackage{graphicx}	%pour l'insertion de figures 
\usepackage{verbatim}		%pour le texte brut 
\usepackage{moreverb}		%text brut avec tab
\usepackage{listings} %aussi pour texte brut
\usepackage{color}
\usepackage{subfigure} %pour des dous-figures
\usepackage{multicol}
\usepackage{geometry}
\usepackage{multirow}
\geometry{margin=1in} % for example, change the margins to 1 inches all round

\addto\captionsfrench{\renewcommand{\chaptername}{Partie}}

% Informations le titre, le(s) auteur (s), la date
\title {TP - Estimation de durées de vie censurées}
\author {Brendan LE LAIN}
\date{\today}

\newtheorem{theorem}{Théorème}

% Début du document
\begin {document}


 
\pagestyle{headings}
 
\maketitle
 
 \addcontentsline{toc}{chapter}{Introduction} 
 \tableofcontents

\chapter* {Introduction}

On se propose d'étudier la durée de vie d'un matériel. On teste ainsi $n$ matériels identiques et leur durée de vie est modélisée par $n$ variables aléatoires $X_i$ $(1 \le i \le n)$, que l'on supposent indépendantes et identiquement distribuées. En fixant un temps de censure $c > 0$, on observe des réalisations $T_i = \min (X_i,c)$.

On suppose de plus que les durées de vie suivent une loi de Weibull de paramètre de forme $\beta >0$ et de paramètre d'échelle $\eta >0$

L'objectif du TP est de mettre en œuvre deux méthodes : celle du maximum de vraisemblance et la méthode SEM pour l'estimation des deux paramètres $\beta$ et $\eta$ à partir de données censurées.

\subsubsection{1.}

Jetons dans un premier temps un œil sur les caractéristiques de la loi de Weibull.

Sa densité s'écrit : 
\[f_{\beta,\eta}(x)=\frac{\beta}{\eta} \left(\frac{x}{\eta}\right)^{\beta-1} \exp\left(-\left(\frac{x}{\eta}\right)^{\beta}\right)\]

La fonction de fiabilité $G_{\beta,\eta}$ est donnée, pour $x>0$, par :
\[G_{\beta,\eta}(x)=1-F_{\beta,\eta}(x)=\exp\left(-\left(\frac{x}{\eta}\right)^{\beta}\right)\]

 Ceci nous permet de calculer le taux de défaillance : 
 \[\lambda_{\beta,\eta}(x)=\frac{f_{\beta,\eta}(x)}{G_{\beta,\eta}(x)}=\frac{\beta}{\eta} \left(\frac{x}{\eta}\right)^{\beta-1}\]
 
 On voit alors immédiatement que :
 
 $\triangleright \; $ si $\beta=1$, $\lambda_{1,\eta}(x)=\frac{1}{\eta}$ et le taux de panne est constant, ce qui ce comprend puisque alors les $X_i$ suivent une loi exponentielle de paramètre $1/\eta$.
 
 $\triangleright \; $ si $\beta<1$, le taux de panne décroit.
 
  $\triangleright \; $ si $\beta>1$, le taux de panne croit.
  
  \subsubsection{2.}
  Notons $M$ le nombre de défaillances effectivement observées. Cette variable aléatoire suit donc une loi binomiale de paramètres $n$ et $p$, où $p$ est la probabilité d’observer une défaillance, c'est-à-dire $p=\mathbb{P}(X_i<c)=1-G_{\beta,\eta}(c)$. Schématiquement, on a donc $M \sim \mathcal{B}(n,1-G_{\beta,\eta}(c))$.
  
  On peut alors calculer simplement l'espérance de cette loi :
  \[\mathbb{E}(M)=n(1-G_{\beta,\eta}(c))\]
  
  
  \chapter {Maximum de vraisemblance}
  
    \section{Analytiquement \label{sec:calculEMV}}
    
    On s'intéresse à présent à la première méthode que nous souhaitons mettre en œuvre : celle du maximum de vraisemblance. Pour cela, il nous faut chercher les estimateurs du maximum de vraisemblance.
    
    Pour un échantillon $(t_1,...,t_n)$ censuré à une censure $c$, la vraisemblance s'écrit :
    
    \begin{align*}
	L(t_1,...,t_n;\beta,\eta) & = \prod_{i:t_i<c} {f_{\beta,\eta}(t_i)}  \prod_{i:t_i=c} {G_{\beta,\eta}(t_i)} \\
	& =  \prod_{i:t_i<c}{\frac{\beta}{\eta} \left(\frac{t_i}{\eta}\right)^{\beta-1}\exp\left(-\left(\frac{t_i}{\eta}\right)^{\beta}\right) }  \prod_{i:t_i=c} {\exp\left(-\left(\frac{t_i}{\eta}\right)^{\beta}\right)}\\
	& = \prod_{i:t_i<c}{\frac{\beta}{\eta} \left(\frac{t_i}{\eta}\right)^{\beta-1} }  \prod_{i=1}^{n} {\exp\left(-\left(\frac{t_i}{\eta}\right)^{\beta}\right)}
	\end{align*}
	
	D'où, avec $m= \# \{t_i | t_i<c\}$  :
	\begin{align*}
	\log L(t_1,...,t_n;\beta,\eta) & = m \log \beta - m\log \eta + (\beta-1)\sum_{i:t_i<c}{\log t_i} - m(\beta-1)\log \eta - \frac{1}{\eta^\beta} \sum_{i=1}^{n} {t_i^\beta}
     \end{align*}
     
     On obtient les équations de vraisemblance :
     \begin{align}
     	\begin{cases}
		\frac{\partial \log L(t_1,...,t_n;\beta,\eta)}{\partial \eta} & = 0 \nonumber\\
	 	\frac{\partial \log L(t_1,...,t_n;\beta,\eta)}{\partial \beta} & = 0 \nonumber\\
     	\end{cases}
     	&\iff 
      	\begin{cases}
		\frac{-m}{\eta} - \frac{m(\beta -1)}{\eta} + \frac{\beta \eta^{\beta-1}}		{\eta^{2\beta}} \sum_{i=1}^{n} {t_i^\beta} = 0  \nonumber\\
	 	\frac{m}{\beta} + \sum_{i:t_i<c}{\log t_i} - m \log \eta + \sum_{i=1}^{n} {\log (\frac{t_i}{\eta}) \frac{t_i^\beta}{\eta^\beta}} = 0  \nonumber\\
     	\end{cases}
   	\\
   	 \nonumber\\
   	&\iff
   	\begin{cases}
     		\frac{-m\beta}{\eta} + \frac{\beta}{\eta^{\beta+1}} \sum_{i=1}^{n} {t_i^\beta} = 0 \nonumber\\
		\frac{m}{\beta} +  \sum_{i:t_i<c}{\log (t_i)} - m\log \eta + \frac{1}{\eta^{\beta}} \sum_{i=1}^{n} {\log (t_i)} t_i^{\beta} - \log \eta \sum_{i=1}^{n} \frac{t_i^\beta}{\eta^\beta}  = 0 \nonumber\\
     	\end{cases}
     	\\
     	 \nonumber\\
     	&\iff
   	\begin{cases}
     		\eta = \left( \frac{1}{m}  \sum_{i=1}^{n} {t_i^\beta} \right)^\frac{1}{\beta} \label{eqEMV}\\
		\frac{1}{\beta} + \frac{1}{m} \sum_{i:t_i<c}{\log (t_i)} - \frac{\sum_{i=1}^{n}  {\log (t_i)} t_i^{\beta}}{\sum_{i=1}^{n} {t_i^{\beta}}}  = 0 
     	\end{cases}
\end{align}

\section{Implémentation \label{sec:impl}}

On peut difficilement résoudre ces équations à la main. On va donc d'abord résoudre numériquement l'équation en $\beta$, pour ensuite obtenir $\eta$.

On présente ci-dessous le code \verb|R| correspondant. On définit dans un premier temps une fonction \verb|f_beta| qui n'est autre que la fonction pour laquelle on souhaite obtenir la racine. Cette fonction prend en paramètres, en plus de la variable $\beta$, noté \verb|b|, l'échantillon observé censuré \verb|ech|, la censure, ainsi que le nombre \verb|nbdef| de défaillances.

 On peut alors définir la fonction \verb|EMV| qui prend en paramètres l'échantillon \verb|t| ainsi que la censure \verb|c|. Cette fonction calcule par \verb|uniroot| la racine de notre fonction \verb|f_beta|, on obtient ainsi $\hat{\beta}$ l'estimateur du maximum de vraisemblance pour $\beta$. Celui pour $\eta$ est obtenu en remplaçant $\beta$ par $\hat{\beta}$ dans l'équation (\ref{eqEMV}). 

\lstset{language=Scilab, frame=single, xrightmargin =0cm , xleftmargin =0 cm, morekeywords={uniroot,rweibull,seq,abline,par,rbind,repeat,hist,sd,next}}
\lstinputlisting[firstline=3, lastline=15]{./EMV.R}

 Remarque importante : lorsque l'échantillon $t$ est totalement censuré, on a $m=0$ et une division par zéro dans la fonction \verb|EMV|. On ne peut donc pas faire tourner la méthode dans ce cas et il faudra gérer cela à l'utilisation.
     
\section{Test}

Pour s'assurer que notre implémentation fonctionne, on peut tester le code précédent pour retrouver numériquement quelques résultats théoriques du maximum de vraisemblance.     
    
\subsection{Convergence}

Le premier est bien sûr la convergence. On vérifie graphiquement que les $\hat{\beta}$ et $\hat{\eta}$ obtenus tendent respectivement vers $\beta$ et $\eta$ avec $n$, taille de l'échantillon. (Le code \verb|R| est en annexe \ref{MV_cv}). On a fait le test ici pour une censure égale à 40, $\beta = 0.5$ et $\eta=100$.

 \begin{figure}[!ht]
	\centering
     	\includegraphics[scale=0.5]{Rplot.png}

	\caption{En rouge, on a tracé les vraies valeurs de $\beta$ (à gauche) et $\eta$ (à droite)}
\end{figure}

\subsection{Normalité asymptotique}

Une autre propriété de l'estimateur du maximum de vraisemblance est qu'il est asymptotiquement normal. Pour le visualiser, on prend une taille d'échantillon $n$ assez grande et on répète $k$ fois la simulation d'une réalisation d'une loi de Weibull censurée sur laquelle on calcule une estimation du maximum de vraisemblance pour $\beta$ et $\eta$. On trace alors l'histogramme des $\beta_k$ et $\eta_k$ obtenus (le code est en annexe \ref{MV_norm}). 

\begin{figure}[!ht]
	\centering
     	\includegraphics[scale=0.5]{Rplot2.png}

	\caption{On a choisit $\beta=1.5$, $\eta=100$, $n=500$ et $k=1000$. Cela ressemble bien à une densité normale.}
\end{figure}

\subsection{Mise à l'épreuve sur notre problème}

Nous pouvons désormais tester la méthode du maximum de vraisemblance sur notre problème et examiner ses qualités, à savoir notamment le biais et la variance de l'estimateur. Nous résumons ci-dessous les résultats pour ces différents tests pour lesquels on simule à chaque fois 50 échantillons avec $\beta=2$, $\eta=100$ et une taille d'échantillon $n=25$. On s'intéresse à l'influence de la censure sur les qualités de l'estimation.

\begin{center}
\begin{tabular}{|c||c|c||c|c|}
	\hline
	\bf Censure &  $\mathbb{E}(\hat{\beta})$  &  $Var(\hat{\beta})$ &  $\mathbb{E}(\hat{\eta})$ &  $Var(\hat{\eta})$ \\
	\hline
	\bf 40 &2.66 & 2.41 & 137.08 &16627.64 \\
	\hline
	\bf 60 &2.19 & 0.69 & 108.19 & 1074.97\\
	\hline
	\bf 80 &1.99 & 0.28 &109.02 &1706.83 \\
	\hline
	\bf 100 &2.25 &0.32  & 99.90&  127.20\\
	\hline
\end{tabular}
\end{center}

On peut observer que la variance augmente fortement lorsque les données sont fortement censurés (de l'ordre de 40).

Cela nous incline à chercher une autre méthode prenant mieux en compte le manque d'information. 

  \chapter {Méthode SEM}
  
  \section{Analytiquement}
  
  L'idée est de palier au manque d'information lié à la censure en simulant ces données manquantes, sachant que la défaillance a lieu après la censure. Partant de paramètres $\beta_0$ et $\eta_0$ arbitraires, nous simulerons les données manquantes suivant une loi de Weibull de paramètres $(\beta_0,\eta_0)$ conditionnée par l’événement ${X_i >c}$. Sur ces données complétées, nous pouvons calculer une estimation $(\beta_1,\eta_1)$ des paramètres par la méthode du maximum de vraisemblance. On répète ceci $k$ fois. On peut montrer que la suite $(\beta_k, \eta_k)$ tend avec $n$ (et non avec $k$) vers les vrais paramètres $(\beta,\eta)$.
  
  \subsection{Simulation}
  
  Le premier problème qui se pose ici est donc celui de la simulation des données manquantes. Pour cela on utilise la méthode de la fonction inverse, qui se base sur le théorème suivant : 
  
 \begin{theorem}
Soit $F$ la fonction de répartition continue d'une variable aléatoire réelle $X$. 

On a $F(X) \sim \mathcal{U}_{[0,1]}$
\end{theorem}
  
 On en déduit immédiatement que $F^{-1}(U)$ a la même loi que X, où $U\sim\mathcal{U}_{[0,1]}$. 
 
Dans notre cas, on souhaite simuler des données qui suivent une loi de Weibull de paramètres $(\beta_0,\eta_0)$ conditionnée par ${X>c}$. Cela donne une fonction de répartition $F$ de la forme :
 
 \begin{align*}
 F(x) & =  \mathbb{P}(X \leq x | X > c) = \frac{\mathbb{P}(c \leq X \leq x)}{\mathbb{P}(X>c)} 
= \frac{\mathbb{P} (X \leq x) - \mathbb{P}(X<c)}{\mathbb{P}(X>c)} \\
&= \frac{1-\exp{(-(\frac{x}{\eta})^{\beta})} - 1 + \exp{(-(\frac{c}{\eta})^{\beta}})}{\exp{(-(\frac{c}{\eta})^{\beta}})} \\
&= 1 - \exp{\left( \frac{-x^{\beta}+c^{\beta}}{\eta^{\beta}} \right)}
\end{align*}

D'après le théorème précédent, on sait que cette expression suit une loi uniforme sur $[0,1]$.
Et que l'inverse est précisément la loi de nos données manquantes. 
Alors, avec $U \sim \mathcal{U}_{[0,1]} $ , on obtient : 

\[
u = 1 - \exp{\frac{-x^{\beta}+c^{beta}}{\eta^{\beta}}}
\implies \ln (1-u) = \frac{-x^{\beta}+c^{\beta}}{\eta^{\beta}}
\implies x = \left( -\eta^{\beta} \ln{(1-u)} + c^{\beta} \right) ^{\frac{1}{\beta}}  
\]

Ou encore, en remarquant que $U \sim \mathcal{U}_{[0,1]}$ équivaut à $1-U \sim \mathcal{U}_{[0,1]}$ : 

\begin{align*}
x &= \left( \eta^\beta ( -\ln{(u)} + \frac{c^\beta}{\eta^\beta}) \right) ^{\frac{1}{\beta}}\\
&= \eta \left(-\ln{(u)} + (\frac{c}{\eta})^\beta \right)^{\frac{1}{\beta}}
\end{align*}

\subsection{Calcul de l'EMV}
Le deuxième problème que l'on rencontre est le calcul de l'estimateur de maximum de vraisemblance
pour ces données non tronquées. Elles suivent une loi de Weibull de paramètres $(\beta,\eta)$. 
D'où l'expression de la vraisemblance : 

\[
L(x_1,...,x_n;\beta,\eta)  = \prod_{i=1}^{n} {f_{\beta,\eta}(x_i)} =  \prod_{i=1}^{n}{\frac{\beta}{\eta} \left(\frac{x_i}{\eta}\right)^{\beta-1}\exp\left(-\left(\frac{x_i}{\eta}\right)^{\beta}\right) }
\]


D'où : 
\begin{align*}
\log L(x_1,...,x_n;\beta,\eta) &= \sum_{i=1}^{n} \log \left( \frac{\beta}{\eta} \left(\frac{x_i}{\eta}\right)^{\beta-1}\exp\left(-\left(\frac{x_i}{\eta}\right)^{\beta}\right) \right) \\
&= n \log (\beta) - n \log (\eta) + (\beta -1 ) \sum_{i=1}^{n} \log (x_i) -n (\beta -1) \log (\eta) - \sum_{i=1}^{n} (\frac{x_i}{\eta})^\beta \\
\end{align*}

En dérivant l'expression précédente par rapport à $\beta$ d'un côté et par rapport à $\eta$ de l'autre et après des calculs ressemblant fort à ceux réalisés au paragraphe (\ref{sec:calculEMV}), on obtient les équations de 
vraisemblance suivantes : 
 
\[
\begin{cases}
\eta = \left( \frac{1}{n}  \sum_{i=1}^{n} {x_i^\beta} \right)^{\frac{1}{\beta}}\\
\frac{1}{\beta} + \frac{1}{n} \sum_{i=1}^{n}{\log (x_i)} - \frac{\sum_{i=1}^{n}  {\log (x_i)} x_i^{\beta}}{\sum_{i=1}^{n} {x_i^{\beta}}}  = 0  
\end{cases}
\]

Similairement à ce qu'on avait fait plus haut, on obtient les estimateurs $\hat{\beta}$ et $\hat{\eta}$ du maximum de vraisemblance pour les données simulées non tronquées qui forment donc le couple $(\beta_k,\eta_k)$ définit au début de cette section. 


\subsection{Critère d'arrêt}

Enfin, il nous reste à voir à quel moment arrêter la construction des $\beta_k$ et $\eta_k$. 
Une idée est de s'arrêter lorsque la suite s'est stabilisée, c'est-à-dire lorsque $(\beta_{k+1},\eta_{k+1})$ est \emph{proche} de $(\beta_k,\eta_k)$. Le moyen de mesurer cette proximité qui vient à l'esprit est la vraisemblance de l'échantillon de départ. On aura ainsi le critère d'arrêt suivant : 

\[ | L(t_1,...,t_n;\beta_k,\eta_k) - L(t_1,...,t_n;\beta_{k+1},\eta_{k+1} | \leq \epsilon \]
Pour $\epsilon$ un réel positif donné. En fait on prendra la log-vraisemblance, simplement pour
avoir des expressions plus simples.

\section{Implémentation \label{sec:impl2}}

Nous avons maintenant tout ce qu'il nous faut. Le code implémentant la méthode SEM décrite dans le paragraphe précédent est détaillé ci-dessous.

La fonction \verb|simu| simule \verb|N| valeurs suivant une loi de Weibull de paramètres \verb|beta0| et \verb|eta0|, conditionnée par $X>c$.

\lstinputlisting[firstline=4, lastline=8]{./SEM.R}

Les fonctions \verb|f_beta_SEM| et \verb|EMV_SEM| calculent l'estimateur du maximum de vraisemblance pour les paramètres $(\beta,\eta)$ d'une loi de Weibull non tronquée. 
\lstinputlisting[firstline=20, lastline=32]{./SEM.R}

La fonction \verb|logVrai| renvoie la valeur de la log-vraisemblance d'un échantillon suivant une loi de Weibull de paramètres \verb|beta| et \verb|eta| censurée à \verb|c|.
\lstinputlisting[firstline=12, lastline=17]{./SEM.R}

Finalement, la fonction \verb|SEM| calcule les estimateurs de $\beta$ et $\eta$ par la méthode SEM. Elle prend en entrée l'échantillon censuré \verb|t| et la censure \verb|c|, ainsi que des paramètres optionnels permettant de jouer sur les valeurs de $\beta_0, \eta_0$ et $\epsilon$. Par sécurité, l'algorithme s'arrête après \verb|iterMax| itérations (30 par défaut).
 \lstinputlisting[firstline=34, lastline=57]{./SEM.R}
 
 \section{Test}
 
 \subsection{Convergence}
 
 Comme nous l'avions fait pour la méthode du maximum de vraisemblance, nous pouvons observer graphiquement la convergence de la méthode SEM. Les graphiques ci-dessous sont réalisés avec une censure égale à 40, $\beta=0.5$ et $\eta=100$ (le code est en annexe \ref{SEM_cv}).
 
\begin{figure}[!ht]
	\centering
     	\includegraphics[scale=0.45]{Rplot3.png}

	\caption{En rouge, on a tracé les vraies valeurs de $\beta$ (à gauche) et $\eta$ (à droite)}
\end{figure}  

 \subsection{Loi des estimateurs}
 
 On peut se demander si la loi des estimateurs SEM est, comme pour la méthode du maximum de vraisemblance, asymptotiquement normale. Comme pour la méthode MV, on peut tenter de le visualiser avec un histogramme (le code de la figure suivante est en annexe \ref{SEM_norm}). 
 
 \begin{figure}[!ht]
	\centering
     	\includegraphics[scale=0.42]{Rplot4.png}

	\caption{On a choisit $\beta=1.5$, $\eta=100$, $n=500$ et $k=1000$. Cela ressemble fort à une densité normale.}
\end{figure}
  
\chapter{Comparaison des deux méthodes}

 On peut à présent comparer les résultats obtenus pour chacune des deux méthodes et voir si la méthode SEM permet de gagner quelque chose par rapport à celle du maximum de vraisemblance. 
 
 On choisit une taille d'échantillon fixe $n=25$ (on avait vu que c'était pour de petits échantillons que la méthode du maximum de vraisemblance (MV) pouvait flancher), une censure égale à 40 et $\eta=100$. On réalise les expériences pour 4 valeurs différentes de $\beta$. On simule à chaque fois 50 échantillons sur lesquels on calcule le nombre moyen de défaillances (noté M), la moyenne et l'écart-type pour les deux méthodes. Les résultats sont réunis dans le tableau suivant (le code est en annexe \ref{comp}).
 
 \begin{center}
\begin{tabular}{|c||c||c|c|c|c||c|c|c|c|}
	\hline
	\bf \multirow{2}{1.5cm}{Loi de Weibull} & \multirow{2}{1cm}{$\mathbb{E}(M)$} & \multicolumn{4}{c||}{\bf Méthode MV} & \multicolumn{4}{c|}{ \bf Méthode SEM} \\

	\cline{3-10}
	& & $\mathbb{E}(\hat{\beta})$  &  $\sigma(\hat{\beta})$ &  $\mathbb{E}(\hat{\eta})$ &  $\sigma(\hat{\eta})$ & $\mathbb{E}(\hat{\beta})$  &  $\sigma(\hat{\beta})$ &  $\mathbb{E}(\hat{\eta})$ &  $\sigma(\hat{\eta})$ \\
	\hline
	\bf $\beta=0.5, \eta=100$& 11.64 & 0.534 & 0.183 & 152.166 & 211.419 & 0.599 & 0.227 & 122.997& 110.503 \\
	\hline
	\bf $\beta=1.2, \eta=100$ & 6.74 & 1.297 & 0.552& 160.670 & 256.215& 1.707&0.721 &85.576 &31.398 \\
	\hline
	\bf $\beta=2, \eta=100$ &4.06 &2.832 &2.195 &137.148& 167.490& 3.029& 1.274& 80.983&25.759 \\
	\hline
	\bf $\beta=3, \eta=100$ &1.48 &7.044  &10.935 & 148.199 &184.798 &5.474 &3.142 &101.287 &46.926 \\
	\hline
\end{tabular}
\end{center}

Voici comment l'on pourrait commenter ces résultats.

\subsubsection*{Défaillances}
On remarque que le nombre moyen de défaillances diminue avec $\beta$ qui croît. Cela se comprend bien dès que l'on regarde la fonction de fiabilité $G_{\beta,\eta}(c) = \mathbb{P}(X>c) = \exp\left(-\left(\frac{c}{\eta}\right)^{\beta}\right)$, où $X \sim Weibull(\beta,\eta)$. On a, pour une censure $c=40$, les probabilités suivantes : 

\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
\bf $\beta$ & 0.5 & 1.2 & 2 & 3 \\
\hline
\bf $G_{\beta,\eta}(40)$ &0.53 & 0.72 &0.85 &0.94\\
\hline 
 \end{tabular}
 \end{center}
  
On aura donc une forte probabilité d'avoir des échantillons très fortement censurés dans les cas $\beta=2,3$. En effet, dans notre simulation, pour $\beta=3$, on a obtenu 9 échantillons (sur 50) totalement censurés. 

Plus précisément, on se souvient (voir l'introduction de ce rapport) que $M$, pris comme une variable aléatoire représentant le nombre de défaillances observées, suit une loi binomiale de paramètre $n$ et $1-G_{\beta,\eta}(c)$. On avait donc   $\mathbb{E}(M)=n(1-G_{\beta,\eta}(c))$. On a alors les valeurs théoriques : 

\begin{center}
\begin{tabular}{|c|c|c|c|c|}
\hline
\bf $\beta$ & 0.5 & 1.2 & 2 & 3 \\
\hline
\bf $n (1- G_{\beta,\eta}(40))$ &11.72 & 7.08 & 3.70 & 1.55\\
\hline 
 \end{tabular}
 \end{center}
 
 Ces valeurs sont bien proches de celles obtenues expérimentalement.
  
\subsubsection*{Méthode MV}

On remarque que l'estimateur du maximum de vraisemblance pour $\beta$ donne de bons résultats pour des échantillons relativement peu censurés ($\beta=0.5,1.2$), avec un écart-type petit. Lorsque le taux de censure devient plus élevé, la méthode a tendance à surestimer fortement le paramètre $\beta$. L'écart-type devient quant à lui important. On peut supposer que cela vient du fait de l'apparition d'estimations aberrantes. Pour un  $\beta=3$ théorique, on a par exemple obtenu une estimation à 60.48. 

Pour l'estimation de $\eta$, on observe des résultats toujours moins bons et avec un écart-type chaque fois bien supérieur à celui obtenu par la méthode SEM. On observe le même phénomène de valeurs totalement \emph{à côté}, par exemple, pour $\beta=3$, on a observé une estimation de $\eta$ à 968.08.

De plus, comme signalé plus haut, avec un taux de censure important, des échantillons totalement censurés apparaissent, sur lesquels on ne peut pas utiliser la méthode MV.

\subsubsection*{Méthode SEM}

Pour l'estimation de $\beta$, la méthode n'a pas donné ici de résultat spectaculaire. On a par contre une plus faible variabilité dès que la censure est très forte. Moins de valeurs aberrantes apparaissent. Pour comparaison, dans le cas $\beta=3$, l'estimation la plus mauvaise observée est 14.69.  

L'estimation de $\eta$ a donné lors de notre expérimentation un net avantage pour la méthode SEM. On n'observe pas de tendance à la surestimation comme pour la méthode MV et l'écart-type reste relativement faible. 

On peut, en forme de conclusion, supposer que la méthode SEM, utilisant dans son algorithme une estimation par maximum de vraisemblance (dont on sait qu'elle ne donne pas de très bons résultats dans le cas d'un faible échantillon), pourrait montrer un avantage encore plus tranché sur des échantillons fortement censurés de taille plus importante. 

  
 \begin{appendix}
 \chapter{Méthode MV - Convergence}
 \label{MV_cv}
 On présente ici le code \verb|R| utilisé pour l'obtention de la figure illustrant la convergence de la méthode du maximum de vraisemblance vers les vrais paramètres. On suppose que les fonctions \verb|f_beta| et \verb|EMV| telles que définies au paragraphe \ref{sec:impl} sont connues de \verb|R|.
  \lstinputlisting[firstline=18, lastline=39]{./EMV.R}
  
   \chapter{Méthode MV - Normalité asymptotique}
 \label{MV_norm}
 Voici le code \verb|R| utilisé pour l'obtention des histogrammes illustrant la normalité asymptotique des estimateurs du maximum de vraisemblance. On suppose que les fonctions \verb|f_beta| et \verb|EMV| sont connues de \verb|R|.
  \lstinputlisting[firstline=43, lastline=64]{./EMV.R}
 
  
   \chapter{Méthode SEM - Convergence}
 \label{SEM_cv}
 On présente ici le code \verb|R| utilisé pour l'obtention de la figure illustrant la convergence de la méthode SEM vers les vrais paramètres. On suppose que les fonctions \verb|simu|, \verb|logVrai|, \verb|f_beta_SEM|, \verb|EMV_SEM| et \verb|SEM| telles que définies au paragraphe \ref{sec:impl2} sont connues de \verb|R|.
  \lstinputlisting[firstline=61, lastline=78]{./SEM.R}
  
   \chapter{Méthode SEM - Normalité asymptotique}
 \label{SEM_norm}
 Voici le code \verb|R| utilisé pour l'obtention des histogrammes illustrant la normalité asymptotique des estimateurs obtenus par la méthode SEM. On suppose que les fonctions \verb|simu|, \verb|logVrai|, \verb|f_beta_SEM|, \verb|EMV_SEM| et \verb|SEM| sont connues de \verb|R|.
  \lstinputlisting[firstline=82, lastline=99]{./SEM.R}
  
  \chapter{Comparaison des méthodes}
  \label{comp}
  Le code suivant permet d'obtenir les résultats tels que présentés dans le tableau de synthèse de la partie 4. On suppose que les fonctions \verb|f_beta|, \verb|EMV|, \verb|simu|, \verb|logVrai|, \verb|f_beta_SEM|, \verb|EMV_SEM| et \verb|SEM| sont connues de \verb|R|. À noter que pour $\beta=2$ (et 3 respectivement) il peut être nécessaire de passer, dans les fonctions \verb|EMV| et \verb|EMV_SEM|, le paramètre \verb|upper| de \verb|uniroot| à 20 (respectivement 60, voire 70) pour faire face à l'apparition d'estimations abhérantes pour des échantillons fortement censurés. 
  
 Ci-dessous, \verb|M| stocke le nombre de défaillances d'un échantillon, \verb|EMV.est| et \verb|SEM.est| les valeurs des estimations par chacune des deux méthodes. Une variable \verb|total_c| compte le nombre d'échantillons totalement censurés, l'instruction \verb|next| permettant de passer, dans ce cas, à l'échantillon suivant sans calcul par MV rendu impossible (on aurait une division par 0). \verb|Res| stocke sous forme de tableau les moyennes et écart-types qui nous intéressent. 
    \lstinputlisting[firstline=70, lastline=99]{./testMethodes.R}
    
  \end{appendix}

\end{document}